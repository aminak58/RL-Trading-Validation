{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MtfScalper RL Feature Engineering Analysis\n",
    "## تحلیل و بررسی ویژگی‌های RL برای بهینه‌سازی خروج\n",
    "\n",
    "این نوت‌بوک برای:\n",
    "1. تحلیل اهمیت ویژگی‌ها\n",
    "2. بررسی همبستگی بین features\n",
    "3. ارزیابی کیفیت سیگنال‌های خروج\n",
    "4. تنظیم پارامترهای reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Freqtrade imports\n",
    "try:\n",
    "    from freqtrade.data.history import load_pair_history\n",
    "    FREQTRADE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    FREQTRADE_AVAILABLE = False\n",
    "    print(\"Freqtrade not available, using alternative data loading\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Freqtrade available: {FREQTRADE_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PAIR = \"BTC/USDT:USDT\"\n",
    "TIMEFRAME = \"5m\"\n",
    "DATA_PATH = \"user_data/data/binance\"\n",
    "\n",
    "# Try to load data using Freqtrade\n",
    "if FREQTRADE_AVAILABLE:\n",
    "    try:\n",
    "        df = load_pair_history(\n",
    "            datadir=Path(DATA_PATH),\n",
    "            timeframe=TIMEFRAME,\n",
    "            pair=PAIR,\n",
    "            data_format='json',\n",
    "            candle_type='futures'\n",
    "        )\n",
    "        print(f\"Loaded {len(df)} candles for {PAIR} using Freqtrade\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading with Freqtrade: {e}\")\n",
    "        FREQTRADE_AVAILABLE = False\n",
    "\n",
    "# Alternative: Generate sample data if Freqtrade not available\n",
    "if not FREQTRADE_AVAILABLE or df is None:\n",
    "    print(\"Generating sample data for analysis...\")\n",
    "    \n",
    "    # Generate sample price data\n",
    "    np.random.seed(42)\n",
    "    periods = 5000\n",
    "    base_price = 60000\n",
    "    \n",
    "    # Generate realistic price movements\n",
    "    returns = np.random.normal(0.0001, 0.02, periods)\n",
    "    prices = [base_price]\n",
    "    \n",
    "    for ret in returns:\n",
    "        new_price = prices[-1] * (1 + ret)\n",
    "        prices.append(new_price)\n",
    "    \n",
    "    # Create OHLCV data\n",
    "    timestamps = pd.date_range(start='2024-01-01', periods=periods, freq='5T')\n",
    "    \n",
    "    data = {\n",
    "        'open': prices[:-1],\n",
    "        'high': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices[:-1]],\n",
    "        'low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices[:-1]],\n",
    "        'close': prices[1:],\n",
    "        'volume': np.random.lognormal(10, 1, periods)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data, index=timestamps)\n",
    "    print(f\"Generated {len(df)} sample candles\")\n",
    "\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"Price range: ${df['close'].min():.0f} - ${df['close'].max():.0f}\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Apply all feature engineering for RL exit optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic indicators\n",
    "    try:\n",
    "        import talib.abstract as ta\n",
    "        TALIB_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        TALIB_AVAILABLE = False\n",
    "        print(\"TA-Lib not available, using manual calculations\")\n",
    "    \n",
    "    if TALIB_AVAILABLE:\n",
    "        # EMAs\n",
    "        df['ema_9'] = ta.EMA(df, timeperiod=9)\n",
    "        df['ema_21'] = ta.EMA(df, timeperiod=21)\n",
    "        df['ema_200'] = ta.EMA(df, timeperiod=200)\n",
    "        \n",
    "        # RSI\n",
    "        df['rsi'] = ta.RSI(df, timeperiod=14)\n",
    "        \n",
    "        # ATR\n",
    "        df['atr'] = ta.ATR(df, timeperiod=14)\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['bb_upper'], df['bb_middle'], df['bb_lower'] = ta.BBANDS(df, timeperiod=20)\n",
    "    else:\n",
    "        # Manual calculations\n",
    "        # EMAs\n",
    "        df['ema_9'] = df['close'].ewm(span=9).mean()\n",
    "        df['ema_21'] = df['close'].ewm(span=21).mean()\n",
    "        df['ema_200'] = df['close'].ewm(span=200).mean()\n",
    "        \n",
    "        # RSI\n",
    "        delta = df['close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # ATR\n",
    "        high_low = df['high'] - df['low']\n",
    "        high_close = np.abs(df['high'] - df['close'].shift())\n",
    "        low_close = np.abs(df['low'] - df['close'].shift())\n",
    "        true_range = np.maximum(high_low, np.maximum(high_close, low_close))\n",
    "        df['atr'] = true_range.rolling(window=14).mean()\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['bb_middle'] = df['close'].rolling(window=20).mean()\n",
    "        df['bb_std'] = df['close'].rolling(window=20).std()\n",
    "        df['bb_upper'] = df['bb_middle'] + (df['bb_std'] * 2)\n",
    "        df['bb_lower'] = df['bb_middle'] - (df['bb_std'] * 2)\n",
    "    \n",
    "    # ═══════════════════════════════════════════════\n",
    "    # Exit-Specific Features\n",
    "    # ═══════════════════════════════════════════════\n",
    "    \n",
    "    # Price momentum\n",
    "    df['momentum_5'] = df['close'].pct_change(5)\n",
    "    df['momentum_10'] = df['close'].pct_change(10)\n",
    "    df['momentum_20'] = df['close'].pct_change(20)\n",
    "    \n",
    "    # Acceleration\n",
    "    df['acceleration'] = df['momentum_5'].diff()\n",
    "    \n",
    "    # Distance from recent high/low\n",
    "    df['dist_from_high_20'] = (df['high'].rolling(20).max() - df['close']) / df['close']\n",
    "    df['dist_from_low_20'] = (df['close'] - df['low'].rolling(20).min()) / df['close']\n",
    "    \n",
    "    # Volume patterns\n",
    "    df['volume_ratio_5'] = df['volume'] / df['volume'].rolling(5).mean()\n",
    "    df['volume_ratio_20'] = df['volume'] / df['volume'].rolling(20).mean()\n",
    "    \n",
    "    # Spread proxy\n",
    "    df['spread_proxy'] = (df['high'] - df['low']) / df['close']\n",
    "    df['spread_ma_ratio'] = df['spread_proxy'] / df['spread_proxy'].rolling(20).mean()\n",
    "    \n",
    "    # RSI Divergence\n",
    "    price_higher = df['close'] > df['close'].shift(10)\n",
    "    rsi_lower = df['rsi'] < df['rsi'].shift(10)\n",
    "    df['bearish_divergence'] = (price_higher & rsi_lower).astype(int)\n",
    "    \n",
    "    price_lower = df['close'] < df['close'].shift(10)\n",
    "    rsi_higher = df['rsi'] > df['rsi'].shift(10)\n",
    "    df['bullish_divergence'] = (price_lower & rsi_higher).astype(int)\n",
    "    \n",
    "    # Support/Resistance\n",
    "    df['pivot'] = (df['high'] + df['low'] + df['close']) / 3\n",
    "    df['r1'] = 2 * df['pivot'] - df['low']\n",
    "    df['s1'] = 2 * df['pivot'] - df['high']\n",
    "    df['dist_to_r1'] = (df['r1'] - df['close']) / df['close']\n",
    "    df['dist_to_s1'] = (df['close'] - df['s1']) / df['close']\n",
    "    \n",
    "    # Risk score\n",
    "    df['risk_score'] = (\n",
    "        df['spread_proxy'] * 0.3 +\n",
    "        (1 / (df['volume_ratio_5'] + 0.1)) * 0.3 +\n",
    "        df['atr'] / df['close'] * 0.4\n",
    "    )\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "# Apply features\n",
    "df = apply_feature_engineering(df)\n",
    "print(f\"Created {len(df.columns)} features\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance based on correlation with future returns\n",
    "def calculate_feature_importance(df, target_periods=[5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Calculate feature importance for different prediction horizons\n",
    "    \"\"\"\n",
    "    importance_dict = {}\n",
    "    \n",
    "    feature_cols = [\n",
    "        'momentum_5', 'momentum_10', 'momentum_20', 'acceleration',\n",
    "        'dist_from_high_20', 'dist_from_low_20', 'volume_ratio_5',\n",
    "        'volume_ratio_20', 'spread_proxy', 'bearish_divergence',\n",
    "        'bullish_divergence', 'risk_score', 'rsi', 'atr'\n",
    "    ]\n",
    "    \n",
    "    for period in target_periods:\n",
    "        # Calculate future returns\n",
    "        df[f'future_return_{period}'] = df['close'].shift(-period) / df['close'] - 1\n",
    "        \n",
    "        # Calculate correlations\n",
    "        correlations = {}\n",
    "        for feature in feature_cols:\n",
    "            if feature in df.columns:\n",
    "                corr = df[feature].corr(df[f'future_return_{period}'])\n",
    "                correlations[feature] = abs(corr) if not pd.isna(corr) else 0\n",
    "        \n",
    "        importance_dict[f'{period}_candles'] = correlations\n",
    "    \n",
    "    return pd.DataFrame(importance_dict)\n",
    "\n",
    "importance_df = calculate_feature_importance(df)\n",
    "importance_df = importance_df.sort_values('10_candles', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Results:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot importance\n",
    "if len(importance_df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    importance_df.head(10).plot(kind='barh', ax=ax)\n",
    "    plt.title('Feature Importance for Exit Timing (Top 10)', fontsize=14)\n",
    "    plt.xlabel('Absolute Correlation with Future Returns')\n",
    "    plt.ylabel('Features')\n",
    "    plt.legend(title='Prediction Horizon')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nTop 5 Most Important Features (10 candles):\")\n",
    "    print(importance_df['10_candles'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exit Signal Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_exit_signals(df):\n",
    "    \"\"\"\n",
    "    Analyze potential exit points based on various conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define exit conditions\n",
    "    exit_conditions = {\n",
    "        'RSI_Overbought': df['rsi'] > 70,\n",
    "        'RSI_Oversold': df['rsi'] < 30,\n",
    "        'Bearish_Divergence': df['bearish_divergence'] == 1,\n",
    "        'Bullish_Divergence': df['bullish_divergence'] == 1,\n",
    "        'High_Risk_Score': df['risk_score'] > df['risk_score'].quantile(0.8),\n",
    "        'Low_Volume': df['volume_ratio_5'] < 0.5,\n",
    "        'Price_At_Resistance': df['dist_to_r1'] < 0.005,\n",
    "        'Price_At_Support': df['dist_to_s1'] < 0.005,\n",
    "        'High_Momentum': df['momentum_5'] > 0.02,\n",
    "        'Negative_Momentum': df['momentum_5'] < -0.02\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for condition_name, condition in exit_conditions.items():\n",
    "        # Calculate returns after signal\n",
    "        signal_indices = df[condition].index\n",
    "        \n",
    "        if len(signal_indices) > 0:\n",
    "            returns_5 = []\n",
    "            returns_10 = []\n",
    "            \n",
    "            for idx in signal_indices[:-20]:  # Avoid end of dataframe\n",
    "                loc = df.index.get_loc(idx)\n",
    "                if loc + 10 < len(df):\n",
    "                    ret_5 = (df.iloc[loc + 5]['close'] - df.iloc[loc]['close']) / df.iloc[loc]['close']\n",
    "                    ret_10 = (df.iloc[loc + 10]['close'] - df.iloc[loc]['close']) / df.iloc[loc]['close']\n",
    "                    returns_5.append(ret_5)\n",
    "                    returns_10.append(ret_10)\n",
    "            \n",
    "            results[condition_name] = {\n",
    "                'count': len(signal_indices),\n",
    "                'frequency': len(signal_indices) / len(df),\n",
    "                'avg_return_5': np.mean(returns_5) if returns_5 else 0,\n",
    "                'avg_return_10': np.mean(returns_10) if returns_10 else 0,\n",
    "                'win_rate_5': sum(1 for r in returns_5 if r > 0) / len(returns_5) if returns_5 else 0\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "exit_analysis = analyze_exit_signals(df)\n",
    "exit_analysis = exit_analysis.sort_values('avg_return_10', ascending=False)\n",
    "\n",
    "print(\"Exit Signal Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(exit_analysis)\n",
    "\n",
    "# Visualize\n",
    "if len(exit_analysis) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot 1: Average returns\n",
    "    exit_analysis[['avg_return_5', 'avg_return_10']].plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Average Returns After Exit Signal')\n",
    "    axes[0].set_ylabel('Return (%)')\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Plot 2: Signal frequency vs win rate\n",
    "    axes[1].scatter(exit_analysis['frequency'], exit_analysis['win_rate_5'], s=100)\n",
    "    for idx, row in exit_analysis.iterrows():\n",
    "        axes[1].annotate(idx, (row['frequency'], row['win_rate_5']), fontsize=8)\n",
    "    axes[1].set_xlabel('Signal Frequency')\n",
    "    axes[1].set_ylabel('Win Rate (5 candles)')\n",
    "    axes[1].set_title('Signal Frequency vs Win Rate')\n",
    "    axes[1].axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Timeframe Alignment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mtf_alignment(df):\n",
    "    \"\"\"\n",
    "    Analyze the quality of multi-timeframe alignment signals\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate MTF conditions\n",
    "    df['trend_5m'] = (df['ema_9'] > df['ema_21']).astype(int)\n",
    "    \n",
    "    # Resample for higher timeframes\n",
    "    df_15m = df.resample('15T').agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "    \n",
    "    df_1h = df.resample('1H').agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # Calculate higher TF trends\n",
    "    df_15m['ema_9'] = df_15m['close'].ewm(span=9).mean()\n",
    "    df_15m['ema_21'] = df_15m['close'].ewm(span=21).mean()\n",
    "    df_15m['trend'] = (df_15m['ema_9'] > df_15m['ema_21']).astype(int)\n",
    "    \n",
    "    df_1h['ema_9'] = df_1h['close'].ewm(span=9).mean()\n",
    "    df_1h['ema_21'] = df_1h['close'].ewm(span=21).mean()\n",
    "    df_1h['trend'] = (df_1h['ema_9'] > df_1h['ema_21']).astype(int)\n",
    "    \n",
    "    # Merge trends back\n",
    "    df['trend_15m'] = df_15m['trend'].reindex(df.index, method='ffill')\n",
    "    df['trend_1h'] = df_1h['trend'].reindex(df.index, method='ffill')\n",
    "    \n",
    "    # Calculate alignment\n",
    "    df['mtf_aligned_long'] = (\n",
    "        (df['trend_5m'] == 1) &\n",
    "        (df['trend_15m'] == 1) &\n",
    "        (df['trend_1h'] == 1)\n",
    "    )\n",
    "    \n",
    "    df['mtf_aligned_short'] = (\n",
    "        (df['trend_5m'] == 0) &\n",
    "        (df['trend_15m'] == 0) &\n",
    "        (df['trend_1h'] == 0)\n",
    "    )\n",
    "    \n",
    "    # Analyze performance of aligned signals\n",
    "    aligned_long_signals = df[df['mtf_aligned_long']].index\n",
    "    aligned_short_signals = df[df['mtf_aligned_short']].index\n",
    "    \n",
    "    results = {\n",
    "        'Total_Candles': len(df),\n",
    "        'Aligned_Long_Count': len(aligned_long_signals),\n",
    "        'Aligned_Short_Count': len(aligned_short_signals),\n",
    "        'Aligned_Long_%': len(aligned_long_signals) / len(df) * 100,\n",
    "        'Aligned_Short_%': len(aligned_short_signals) / len(df) * 100\n",
    "    }\n",
    "    \n",
    "    # Calculate returns after alignment\n",
    "    if len(aligned_long_signals) > 0:\n",
    "        long_returns = []\n",
    "        for idx in aligned_long_signals[:-20]:\n",
    "            loc = df.index.get_loc(idx)\n",
    "            if loc + 20 < len(df):\n",
    "                ret = (df.iloc[loc + 20]['close'] - df.iloc[loc]['close']) / df.iloc[loc]['close']\n",
    "                long_returns.append(ret)\n",
    "        results['Avg_Long_Return_20'] = np.mean(long_returns) if long_returns else 0\n",
    "    \n",
    "    if len(aligned_short_signals) > 0:\n",
    "        short_returns = []\n",
    "        for idx in aligned_short_signals[:-20]:\n",
    "            loc = df.index.get_loc(idx)\n",
    "            if loc + 20 < len(df):\n",
    "                ret = (df.iloc[loc]['close'] - df.iloc[loc + 20]['close']) / df.iloc[loc]['close']\n",
    "                short_returns.append(ret)\n",
    "        results['Avg_Short_Return_20'] = np.mean(short_returns) if short_returns else 0\n",
    "    \n",
    "    return results\n",
    "\n",
    "mtf_results = analyze_mtf_alignment(df)\n",
    "\n",
    "print(\"Multi-Timeframe Alignment Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in mtf_results.items():\n",
    "    if '%' in key or 'Return' in key:\n",
    "        print(f\"{key}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:,}\")\n",
    "\n",
    "# Visualize MTF alignment\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(df.index[-500:], df['close'][-500:], label='Price', alpha=0.7)\n",
    "ax.scatter(df[df['mtf_aligned_long']].index[-50:], df[df['mtf_aligned_long']]['close'][-50:], \n",
    "           color='green', label='Aligned Long', alpha=0.8, marker='^')\n",
    "ax.scatter(df[df['mtf_aligned_short']].index[-50:], df[df['mtf_aligned_short']]['close'][-50:], \n",
    "           color='red', label='Aligned Short', alpha=0.8, marker='v')\n",
    "ax.set_title('MTF Alignment Signals (Last 500 Candles)')\n",
    "ax.set_ylabel('Price')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reward Function Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_reward_function(df, weights):\n",
    "    \"\"\"\n",
    "    Simulate different reward function weight combinations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate trades\n",
    "    trades = []\n",
    "    in_position = False\n",
    "    entry_price = 0\n",
    "    entry_idx = 0\n",
    "    max_profit = 0\n",
    "    \n",
    "    for i in range(100, len(df) - 20):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        # Simple entry condition\n",
    "        if not in_position and row['momentum_5'] > 0 and row['rsi'] < 70:\n",
    "            in_position = True\n",
    "            entry_price = row['close']\n",
    "            entry_idx = i\n",
    "            max_profit = 0\n",
    "        \n",
    "        elif in_position:\n",
    "            current_profit = (row['close'] - entry_price) / entry_price\n",
    "            max_profit = max(max_profit, current_profit)\n",
    "            \n",
    "            # Calculate reward components\n",
    "            profit_score = min(10, max(-10, current_profit * 100))\n",
    "            \n",
    "            # Drawdown from max profit\n",
    "            drawdown = max_profit - current_profit if max_profit > 0 else 0\n",
    "            drawdown_score = -5 * drawdown if drawdown > 0.01 else 5\n",
    "            \n",
    "            # Timing score (simplified)\n",
    "            position_duration = i - entry_idx\n",
    "            timing_score = 5 if position_duration < 50 else -position_duration * 0.01\n",
    "            \n",
    "            # Risk/Reward (simplified)\n",
    "            rr_score = 3 if current_profit > 0.01 else -1\n",
    "            \n",
    "            # Calculate total reward\n",
    "            total_reward = (\n",
    "                weights['profit'] * profit_score +\n",
    "                weights['drawdown'] * drawdown_score +\n",
    "                weights['timing'] * timing_score +\n",
    "                weights['risk_reward'] * rr_score\n",
    "            )\n",
    "            \n",
    "            # Exit decision based on reward\n",
    "            if total_reward < -5 or position_duration > 100 or current_profit > 0.03:\n",
    "                trades.append({\n",
    "                    'entry_idx': entry_idx,\n",
    "                    'exit_idx': i,\n",
    "                    'duration': position_duration,\n",
    "                    'profit': current_profit,\n",
    "                    'max_profit': max_profit,\n",
    "                    'drawdown': drawdown,\n",
    "                    'reward': total_reward\n",
    "                })\n",
    "                in_position = False\n",
    "    \n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "# Test different weight combinations\n",
    "weight_combinations = [\n",
    "    {'profit': 0.35, 'drawdown': 0.25, 'timing': 0.20, 'risk_reward': 0.20},  # Balanced\n",
    "    {'profit': 0.50, 'drawdown': 0.20, 'timing': 0.15, 'risk_reward': 0.15},  # Profit focused\n",
    "    {'profit': 0.25, 'drawdown': 0.40, 'timing': 0.20, 'risk_reward': 0.15},  # Risk focused\n",
    "    {'profit': 0.30, 'drawdown': 0.20, 'timing': 0.35, 'risk_reward': 0.15},  # Timing focused\n",
    "]\n",
    "\n",
    "results_comparison = []\n",
    "\n",
    "for i, weights in enumerate(weight_combinations):\n",
    "    trades = simulate_reward_function(df, weights)\n",
    "    \n",
    "    if len(trades) > 0:\n",
    "        results_comparison.append({\n",
    "            'Config': f\"Config_{i+1}\",\n",
    "            'Total_Trades': len(trades),\n",
    "            'Avg_Profit': trades['profit'].mean() * 100,\n",
    "            'Win_Rate': (trades['profit'] > 0).mean() * 100,\n",
    "            'Avg_Duration': trades['duration'].mean(),\n",
    "            'Max_Drawdown': trades['drawdown'].max() * 100,\n",
    "            'Sharpe': trades['profit'].mean() / trades['profit'].std() if trades['profit'].std() > 0 else 0\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(results_comparison)\n",
    "\n",
    "print(\"Reward Function Weight Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# Visualize comparison\n",
    "if len(comparison_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Metrics to plot\n",
    "    metrics = ['Avg_Profit', 'Win_Rate', 'Avg_Duration', 'Sharpe']\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        if metric in comparison_df.columns:\n",
    "            comparison_df.plot(x='Config', y=metric, kind='bar', ax=ax, legend=False)\n",
    "            ax.set_title(metric.replace('_', ' '))\n",
    "            ax.set_xlabel('')\n",
    "    \n",
    "    plt.suptitle('Reward Function Configuration Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 تحلیل نهایی و توصیه‌ها:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = \"\"\"\n",
    "1. **ویژگی‌های کلیدی برای خروج:**\n",
    "   - Momentum indicators (5-20 candles) بیشترین اهمیت\n",
    "   - Volume patterns نشان‌دهنده کیفیت نقدینگی\n",
    "   - Divergence signals برای تشخیص reversal\n",
    "\n",
    "2. **تنظیمات Reward Function:**\n",
    "   - وزن Profit: 35% (تعادل بین سود و ریسک)\n",
    "   - وزن Drawdown Control: 25% (کنترل ریسک)\n",
    "   - وزن Timing: 20% (خروج در زمان مناسب)\n",
    "   - وزن Risk/Reward: 20% (کیفیت معامله)\n",
    "\n",
    "3. **بهینه‌سازی‌های پیشنهادی:**\n",
    "   - استفاده از Ensemble Models برای predictions\n",
    "   - اضافه کردن Market Regime Detection\n",
    "   - پیاده‌سازی Adaptive Position Sizing\n",
    "\n",
    "4. **Risk Management:**\n",
    "   - Max position duration: 300 candles (25 hours)\n",
    "   - Emergency exit at -3% loss\n",
    "   - Breakeven trigger at +2% profit\n",
    "\n",
    "5. **مراحل بعدی:**\n",
    "   - Phase 2: آموزش مدل RL با داده‌های 18 ماه\n",
    "   - Phase 3: Backtesting و walk-forward analysis\n",
    "   - Phase 4: Paper trading برای 2-4 هفته\n",
    "   - Phase 5: Live deployment با position sizing محدود\n",
    "\"\"\"\n",
    "\n",
    "print(recommendations)\n",
    "\n",
    "# Save analysis results\n",
    "analysis_results = {\n",
    "    'data_info': {\n",
    "        'total_candles': len(df),\n",
    "        'date_range': f\"{df.index[0]} to {df.index[-1]}\",\n",
    "        'price_range': f\"${df['close'].min():.0f} - ${df['close'].max():.0f}\"\n",
    "    },\n",
    "    'feature_count': len(df.columns),\n",
    "    'best_exit_signals': exit_analysis.head(3).to_dict() if len(exit_analysis) > 0 else {},\n",
    "    'mtf_alignment': mtf_results,\n",
    "    'best_reward_config': comparison_df.iloc[0].to_dict() if len(comparison_df) > 0 else {}\n",
    "}\n",
    "\n",
    "import json\n",
    "try:\n",
    "    with open('user_data/notebooks/feature_analysis_results.json', 'w') as f:\n",
    "        json.dump(analysis_results, f, indent=2, default=str)\n",
    "    print(\"\\n✅ Results saved to feature_analysis_results.json\")\n",
    "except:\n",
    "    print(\"\\n⚠️ Could not save results to file\")\n",
    "\n",
    "print(\"\\n🎯 Analysis Complete! Ready for RL model optimization.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
